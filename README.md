# HTML-Webscraping-challenge

## Overview 
In this challenge, the objective is to apply and consolidate the skills acquired in web scraping and data analysis. The focus lies on identifying HTML elements using attributes such as id and class, utilizing both automated browsing with Splinter and HTML parsing with Beautiful Soup. The challenge involves extracting diverse types of information from web pages, including data from HTML tables and recurring elements like multiple news articles. The project encompasses the entire data pipeline, from collecting information on web pages to organizing and storing the data, followed by thorough analysis. 


## Purpose
The ultimate goal is to visually communicate insights derived from the scraped and analyzed data, emphasizing the practical application of core skills in data collection and analysis within a real-world context.
The core skills used for this project are: collecting data, organizing and storing data, analyzing data, and then visually communicating the insights.

<img width="492" alt="image" src="https://github.com/Mitajoshi/HTML-Webscraping-challenge/assets/142932546/66951eff-3ee4-4483-ae2f-8f4df4420174">


## Instructions

The part-1 & part-2 Jupyter Notebooks contain the code and the relevant data gleaned from the Mars Weather Data Table. The table scraped from the Mars Weather Temperature Data Site { https://static.bc-edx.com/data/web/mars_facts/temperature.html } has been stored in a file called "mars_data.csv" in a folder call "data". Both the folder and the csv files get created by the Python code. 
